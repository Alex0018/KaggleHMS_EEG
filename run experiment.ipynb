{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "\n",
    "import gc\n",
    "\n",
    "from src.experiment import experiment, continue_experiment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- REPRODICIBILITY ------------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnasonova-alexandra\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Hawkins/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = ''\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "config = {\n",
    "          'project_name': 'HMS_EEG',\n",
    "          'run_name': f' CombinedSpecs_efficientnet_finetuneAfter2epochs_lrsch0.8_fold{fold}',\n",
    "          'create_dataloaders_func': 'spectrograms_combined',\n",
    "          'data_parameters': {\n",
    "              'batch_size': 100,      \n",
    "              'fold': fold,\n",
    "              'path': 'data/train.csv'       \n",
    "          }  ,\n",
    "          'loss': 'KLDivLoss',\n",
    "          'optimizer': 'Adam', \n",
    "          'learning_rate': 1e-4,\n",
    "          'epochs': 5,\n",
    "          'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "          'model': 'efficientnet_wrapper',\n",
    "          'model_parameters': {\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Kaggle\\HMS_EEG\\wandb\\run-20240402_110605-cttr20iu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nasonova-alexandra/HMS_EEG_efficientnet/runs/cttr20iu' target=\"_blank\">CombinedSpecs_efficientnet_finetuneAfter2epochs_lrsch0.8_fold0</a></strong> to <a href='https://wandb.ai/nasonova-alexandra/HMS_EEG_efficientnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nasonova-alexandra/HMS_EEG_efficientnet' target=\"_blank\">https://wandb.ai/nasonova-alexandra/HMS_EEG_efficientnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nasonova-alexandra/HMS_EEG_efficientnet/runs/cttr20iu' target=\"_blank\">https://wandb.ai/nasonova-alexandra/HMS_EEG_efficientnet/runs/cttr20iu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "   Number of trainable parameters in model:  7686 \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 0 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  1.19778     mean loss  0.94688: 100%|██████████| 1335/1335 [21:11<00:00,  1.05it/s]\n",
      "validation batch:    batch loss  0.61705     mean loss  0.91729: 100%|██████████| 333/333 [07:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.94688\n",
      "\tvalidation:  loss  0.91729\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 1 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  1.33634     mean loss  0.85588: 100%|██████████| 1335/1335 [24:06<00:00,  1.08s/it] \n",
      "validation batch:    batch loss  0.49888     mean loss  0.88218: 100%|██████████| 333/333 [04:55<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.85588\n",
      "\tvalidation:  loss  0.88218\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 2 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  0.31447     mean loss  0.72255: 100%|██████████| 1335/1335 [36:03<00:00,  1.62s/it]\n",
      "validation batch:    batch loss  0.72534     mean loss  0.84164: 100%|██████████| 333/333 [04:20<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.72255\n",
      "\tvalidation:  loss  0.84164\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 3 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  0.20694     mean loss  0.53564: 100%|██████████| 1335/1335 [34:36<00:00,  1.56s/it]\n",
      "validation batch:    batch loss  0.38182     mean loss  0.66873: 100%|██████████| 333/333 [04:23<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.53564\n",
      "\tvalidation:  loss  0.66873\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 4 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  0.48126     mean loss  0.45304: 100%|██████████| 1335/1335 [35:23<00:00,  1.59s/it]\n",
      "validation batch:    batch loss  0.70661     mean loss  0.65710: 100%|██████████| 333/333 [04:25<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.45304\n",
      "\tvalidation:  loss  0.65710\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 5 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  0.33639     mean loss  0.37424: 100%|██████████| 1335/1335 [36:00<00:00,  1.62s/it]\n",
      "validation batch:    batch loss  0.89306     mean loss  0.66581: 100%|██████████| 333/333 [04:30<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.37424\n",
      "\tvalidation:  loss  0.66581\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 6 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  0.80044     mean loss  0.29896: 100%|██████████| 1335/1335 [39:08<00:00,  1.76s/it] \n",
      "validation batch:    batch loss  0.73774     mean loss  0.70521: 100%|██████████| 333/333 [04:56<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain:       loss  0.29896\n",
      "\tvalidation:  loss  0.70521\n",
      "\u001b[1m\u001b[38;5;254m\u001b[48;5;240m Epoch 7 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  training batch:    batch loss  0.26647     mean loss  0.23289:  60%|██████    | 802/1335 [22:53<11:48,  1.33s/it]"
     ]
    }
   ],
   "source": [
    "experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
